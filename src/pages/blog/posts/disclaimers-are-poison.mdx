---
layout: '../../../layouts/Post.astro'
title: Disclaimers are poison
description: Should we be protected from harmful content?
publishDate: December 26, 2023
featuredImage: '/images/blog/disclaimers-are-poison/featured.png'
excerpt: Should we be protected from harmful content?
tags:
  - politics
  - media
  - ethics
---

Should we be protected from harmful content? Most people would say you don't have a rite to be protected from it, but you should be warned so you have a chance to avoid it. Whether it be trigger warnings for common topics that cause PTSD, or age warnings on movies, we have tons of other examples but the principle stands that we have decided some protections from potentially harmful content should be put in place. For most of this article we will be focusing on trigger warnings in media (movies, tv, videos, books, articles etc.). Critics of this practice in general will call these sorts of protections infantilizing, and supporters will call it humane.  I want to talk about the topic in general, and then focus on a few specific outcomes in our expectations that is poisonous to discourse in general, and rational thought in reality.

## Expectations
Generally the strongest of these types of warnings were expected in "safe spaces". In this case I think the warnings are well warranted. For those unaware "safe spaces" are areas that are dedicated to allowing people who have trauma around a topic to be able to get together without being exposed to triggers for that trauma. Some examples would be a woman's support group for domestic violence, alcoholics anonymous, and veteran's support groups. These spaces emphasize comfort and openness with the intention being to allow people to heal from their trauma. Trigger warnings largely started being implemented in these environments as they make a ton of sense to be included as part of these programs. Unfortunately this idea began expanding outside of "safe spaces".

There is an ever more common expectation that all forms of media include these sorts of warnings in depictions of "triggering content". There are several problems with this:

1. Who decides what qualifies as a triggering category of content
2. Who decides if the content itself meets the threshold of being triggering within a category
3. What is "enough" warning

### What Topics?

For the first point it seems to basically be a matter of mob rule. Whatever complaints are heard the loudest tend to end up on the list. Some common examples include:

- Suicide
- Sexual Harassment/rape
- Drug & Alcohol usage
- Racism/Sexism/Ableism
- Depictions of war

There are probably more, but these are some of the common examples of topics. Let's say we agree on these topics being potentially triggering. There are a few main positive arguments for why we should warn against these:

1. These topics when depicted irresponsibly can be glorified; War and drug/alcohol usage would be prime examples where overly simplistic representations of "the glory of war", and "being the life of the party" can cause harm. 
2. These topics when depicted irresponsibly can cause regression; Likewise they can be incredibly tempting to people who for example have substance abuse problems. If I'm an alcoholic and watching tons of people enjoy alcohol it becomes much more likely I will just give in and "have some fun"
3. These topics when depicted irresponsibly can invoke pain; When being reminded of many of the topics in this list people can end up being reminded of horrific circumstances. A rape scene in a movie evoking memories of ones own experience, someone killing themselves remind them of a friend etc.

### What meets the thresholds?
Next is the question of thresholds. Now that we've decided on topics, how do we know what representations are "irresponsible"? Many people would say that **any** representation is irresponsible, and should just be removed, but that's not reasonable. We can't just tell people they're not allowed any depictions of the above. They account for a huge portion of our media, and ultimately the reality is that these topics are important to discuss in media, and in discourse. So who chooses what meets the threshold? I haven't seen any concrete processes to do this, but it seems like a "err on the side of caution" approach. Where possible just include warnings if you're going to cover these topics, and it seems like that's your obligation fulfilled.

### What is Enough Warning?
The last point also drastically changes how these arguments all play out. The most common form of trigger warning exists in a simple warning before content, or around the publication of content (a tweet description for example). For most people this is a sufficient amount of responsibility to place on people. However there are others that say trigger warnings do not go far enough and there needs to be a cut with the content removed, and/or it needs to be removed from all cuts of the content. The problem with just a warning at the beginning would be if someone walks in mid-way through. If you walk-in to a movie halfway through, you won't get the warning. 

So then should we have warnings throughout? On TV often these warnings will play after every ad break, but these natural "breaks" aren't present on every type of media, so what is the expectation here? Again it seems relatively up in the air, but a warning at the beginning would be sufficient. 

### Detractions
As you've probably noticed there's two parallel arguments, 1 for warnings, and 1 for removal. This is where the first critique comes in. As trigger warnings and similar systems have become more popular, people have expanded the argument. After all if you accept it's harmful to people, why should you allow something harmful to be broadcast? Luckily this point already has a lot of pushback, but I figured it's worth mentioning.

Going back to the normal just trigger warning argument, philosophically the primary detracting view I have seen is a combination of the following arguments:

1. Public spaces are not intended to be "safe", it is the responsibility of the individual to remove themselves from the situation, not everyone else to take care of someone
2. People just need to "toughen up", and people should be fine with fictional depictions of things considering they're not real
3. Exposure is the best way to mitigate negative emotions around a topic ([interesting paper](https://journals.sagepub.com/doi/10.1177/21677026231186625))
4. As a producer of content with a ton of other expectations I should not be expected to also determine which things could bother people, and add in warnings

The first three are augments against the principle of warnings in general. The argument shifts the responsibility of both the lack of exposure, and any resulting trauma onto the individual fully. This is a perspective that many have, and can be understandable. There is not always going to be warnings about things you are going to see, and as such the argument that you should "numb" yourself can be seen as one to make people's lives easier. The last one is just a matter of resourcing. Particularly for smaller productions there are already other policies people have to keep in mind, and one more can be a pain. This only matters if we decide that a policy should be in place to **punish** people for not including them.

The counterpoints to these two arguments are that the expectations for everyone to be hardy is not necessarily useful. In many cases we see PTSD and PTSD-like symptoms ruin people's lives, so why would we take PTSD's side in this fight? Trying to encourage strength is one thing, but you don't tell someone to "walk off" a broken leg, instead you wait for it to heal, **then** strengthen it. Likewise trigger warnings could instead be seen as helping people who are not at the **healing** portion of this dynamic yet. The second point could be argued with examples. We already require movies big and small to include a rating. While it may be annoying to do, it's by no means impossible, and there can be a sliding scale of what "level" of production we expect to meet these standards.

## Bigotry of low expectations
The argument for trigger warnings is largely one around context. When we look at the context of who **might** view content we're arguing that those people need to be protected. Arguably if you could find a context where there was no risk, there would be no need for the warnings. For example if a cinema could scan people, determine their age, and only let in people over 18, there's no need for the warning. As such the question for warnings is entirely contextual. Moving from trigger warnings we can look at some pre-emptive warnings.

It is illegal in many countries to claim to be a doctor, or to claim to be giving financial advice. The reason for this is that there are many people who consider these claims to be coming from an "authority". When giving these types of advice you have to make it clear you are not a medical professional so that people understand this is an "uninformed" opinion. This is important in particularly "high-stakes" domains, where the consequences are high.

It could be argued that people who trust these false authorities "get what they deserve". This is typically following the argument that when you lower your expectations people will regress to meet them. From there it's a positive reinforcement loop, where the expectations get lower and lower, and people degrade to meet them. Eventually the argument is that this leads to a sort of permissible illiteracy among people. Once this takes hold it's argued people need to step in to regulate things because people are unable to handle them themselves. This process is called the bigotry of low expectations. However, in a civil society I would argue that something this obliquely predatory should be stopped. There is no reason to allow people to take advantage of others intentionally for a principle, when the practical **real** outcome demonstrably harms people. Not everyone should be expected to be enough of an expert to vet every source, and not everyone should have to bear the consequences of trusting sources that seem legitimate. Instead those people should not be allowed to claim that authority. 

Likewise most of these authorities will have some sort of governing body behind them. If you scam people and you're a doctor, your license can be removed, a lawyer can be disbarred etc. Therefore people should not be able to bring down the "stature" of an institution while lying about their position in it. The same way as someone lying about being a spokesperson for a company is illegal. We now come to an interesting argument as a result of this principle of "stated authorities". Many people comment on various topics, and so with that should people be forced to make a disclaimer at the beginning of their content to state their expertise?
### This blog
When I first started this blog it was to force myself to formalize some of my philosophical ideas, and other opinions. I find this helps for a few reasons:
1. Having to **actually** put something down helps you explore a topic more closely
2. Once it's public it gives you an incentive to do it more properly than private articles would
3. Once it's out there it gives you a chance to come back later and be critical of your work

Never at any point is this blog meant to be a publication in the formal sense. I'm here to write my thoughts, but whether people agree or not is largely irrelevant, other than in those willing to talk about it and expand some of the concepts. I'm not here to be anyone's life coach, a professional philosopher or a writer. My intentions are lined out clearly above, however even with this warning people will assume the latter rather than the former. The question then becomes, should I put a disclaimer on each article to let people know I'm not necessarily a source to look to? Fuck no.

This topic is the primary purpose for this article because it is something I feel quite strongly about. When someone is falsifying their credentials, I think it's fair enough to go after them. Likewise I think for topics where the advice you give is potentially directly harmful for people to follow, you should ideally put in warnings. For example if you're writing a repair guide that could be dangerous, warnings should probably be there. However I think there is a huge misstep currently with where we expect warnings to be on content, and that misstep is leading to people wanting information removed from places. The primary place I see this is in relation to "misinformation".

## Misinformation
Misinformation is defined differently by different people, however for this article I will just claim it to be information that people post where they are knowingly wrong, or intentionally avoid dissent when posting. In these cases we now often see "fact checks", these fact checks exist because it's assumed that the people using these platforms are unable or unwilling to check for themselves. There can be tons of psychological reasons for this, confirmation bias, cognitive dissonance etc. But ultimately because of the impacts this misinformation can have (anti-vax, conspiracies etc.) the argument is that there needs to be a "disclaimer" around it. 

### Get to the point

My problem with this, and the reason why I won't put any warnings on my post is that I disagree with the context. I believe that the need for misinformation tags betrays a bigotry of low expectations. Instead I think people should socially ostracize the sorts of people for whom these statements are made. We cannot wrap the world in bubble-wrap for people, and I do believe that this is a cop out intellectually. If you come across a random blog, or tweet, drop all pretense of accountability and then expect an apology you can fuck yourself. **You are accountable for your beliefs**. We have decided people have the rite to access information, this also means they have the responsibility to vet the information. As stated earlier I am not an expert on many topics, and the reason I don't put disclaimers on things is because there is no reason for someone to **expect** I am. Use your judgement when reading, and take accountability for your beliefs if they cause consequences. 


## Conclusion
Warnings and disclaimers have their place. Whether they're implemented in all forms of media or not there are times they're reasonable. Likewise positive warnings to warn people someone is not an expert is good in certain contexts, however people need accountability. It's not the responsibility of someone creating content to coddle every possible interpretation and context someone might find themselves in. If you are convinced of an argument, and live your life according to it, be prepared to also live with the consequences of it. 
